\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{dsfont}
\author{Alessio Rondelli}
\title{Bayesian Blocks con funzione esponenziale a tratti}

\usepackage[margin=1in]{geometry}

\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}

\begin{document}
\maketitle
\chapter{Report}
\section{Cenni teorici}
Siano dati $t=(t_1,...,t_n)$ e $x=(x_1,...,x_n)$ che corrispondono rispettivamente a una sequenza di reali non-negativi crescente e una sequenza di numeri naturali. Noi cerchiamo di trovare la funzione esponenziale a tratti che ottimizzi una certa funzione di fitness rispetto questi dati. Nello specifico, $t$ è una sequenza temporale e $x$ è una sequenza di valori provenienti da bin.

Dati $t$ e $x$ si cerca di partizionare l'intervallo identificato dalla sequenza temporale $t$ mediante una successione di sottointervalli (chiamati blocchi), in ognuno dei quali si cerca la migliore funzione esponenziale da cui i dati di $x$ provengono.

Nello specifico la funzione esponenziale che cerchiamo di fittare in un blocco è nella forma $\gamma e^{a(t-t_n)},$ dove $t_n$ è l'estremo destro del blocco, $\gamma$ è il valore della funzione alla fine del blocco e $a$ è il termine del decadimento dell'esponenziale. All'interno di ogni blocco si cerca di fittare la funzione ottimizzando i valori $\gamma$ e $a$.

La funzione di fitting scelta è la log-likelihood di cui viene riportata la costruzione nel caso di funzione arbitraria $f(n)$ per generalità.
\begin{theorem}
Sia $t\in\mathbb{R}^n$ successione crescente di tempi reali.
Sia $x\in\mathbb{Z^+}^n$ variabile aleatoria di legge $\bigotimes_{i=1}^{n}Poisson_{f(t_i)}$, dove $f:[t_1,t_n]\rightarrow\mathbb{R}^+$. Evidentemente le marginali sono indipendenti tra loro. Allora la log-likelihood di una realizzazione $\tilde{x}$ sarà:
$$
\log L(\tilde{x}) = \sum_{i=1}^n\tilde{x}_i\log f(t_i) -\sum_{i=1}^n \log(\tilde{x_i!})-\sum_{i=1}^nf(t_i)
$$
\begin{proof}
La likelihood di ognuna delle marginali sarà 
$$
L_i = \frac{f(t_i)^{\tilde{x}_i}e^{-f(t_i)}}{\tilde{x}_i!}
$$
siccome la sua legge è di Poisson. Grazie all'indipendenza tra le componenti di $x$ la likelihood sarà
$$
L = \prod_{i=1}^{n}\frac{f(t_i)^{\tilde{x}_i}e^{-f(t_i)}}{\tilde{x}_i!}.
$$
Passando alla log-liklihood otteniamo
$$
\log L(\tilde{x}) = \sum_{i=1}^{n}\left(\tilde{x}_i\log f(t_i)-f(t_i) -\log(\tilde{x}_i!)\right)
$$
che conclude la dimostrazione.
\end{proof}
\end{theorem}
\begin{remark}
Nel nostro caso useremo la funzione $f(t_i) = \gamma e^{a(t_i-t_n)}$, per cui la nostra log-likelihood sarà
\begin{equation*}
\log L(\tilde{x}) = \sum_{i=1}^n\tilde{x}_i(\log\gamma + a\cdot(t_i-t_n)) -\sum_{i=1}^n \log(\tilde{x_i!})-\sum_{i=1}^n\gamma e^{a(t_i-t_n)}.
\end{equation*}
Forti di questa base teorica si passa alla statistica di Cash, ove l'ultima somma si converte in integrale:
\begin{equation}
\log L(\tilde{x}) = \sum_{i=1}^n\tilde{x}_i(\log\gamma + a\cdot(t_i-t_n)) -\sum_{i=1}^n \log(\tilde{x_i!})-\int_{t_1}^{t_n}\gamma e^{a(t-t_n)} dt.
\end{equation}
\end{remark}
L'uso della log-likelihood è centrale in quanto ci permette di avere la proprietà di additività sui blocchi, che è propedeutica all'uso dell'algoritmo di programmazione dinamica ideato da Scargle. Ripassiamo i passaggi fondamentali di questo algoritmo:
\begin{itemize}
\item Partendo dal primo bin esiste una sola partizione di questo, perciò è nota la partizione ottima di un solo bin.
\item Supponiamo di conoscere la partizione ottima dei primi $R$ bins. Analizzando i primi $R+1$ bins notiamo che grazie alla proprietà di additività delle log-likelihood (o di qualunque funzione di fitness legittima) la partizione ottima sarà divisibile in $2$ parti: la partizione ottima dei primi $r$ bins e l'ultimo blocco che va dal bin $r+1$ fino al bin $R+1$. Di conseguenza per ogni $r$ da $1$ a $R$ calcoliamo la fitness della partizione (che è uguale alla somma delle fitness su ogni blocco della partizione) e selezioniamo $r$ così che massimizzi la fitness della partizione.
\item Abbiamo in questo modo trovato la legge induttiva. Iterando fino a $N$ (il numero di bin) otterremo l'ottima partizione.
\end{itemize}
\begin{remark}
Notiamo che ad ogni passaggio dell'esecuzione si mettono a confronto le log-likelihood delle partizioni dei primi $R$ bins: in particolare indipendentemente dalla funzione di fitting notiamo che è presente un termine che dopo aver fatto la somma sarà costante su ogni partizione: $-\sum_{i=1}^n \log(\tilde{x_i!})$, e, per questa ragione, a fini di massimizzazione può essere ignorato.

Di conseguenza la funzione di fitting che verrà usata nei fatti sarà:
\begin{equation}\label{Cash}
\log L(\tilde{x}) = \sum_{i=1}^n\tilde{x}_i\log(f(t_i)) -\int_{t_1}^{t_n}f(t) dt \\
\end{equation}
e nel nostro caso specifico
\begin{gather}
\log L(\tilde{x}) = \sum_{i=1}^n\tilde{x}_i(\log\gamma + a\cdot(t_i-t_n)) -\int_{t_1}^{t_n}\gamma e^{a(t-t_n)} dt.\label{fitness_exp}
\end{gather}
\end{remark}
Tuttavia notiamo che in generale la log-likelihood dipende dai parametri della funzione da fittare sui dati: ciò comporta la necessità di calcolarli mediante massimizzazione della log-likelihood.
\subsection{Calcolo dei parametri di fitting}
In ogni blocco, che possiamo identificare matematicamente come una realizzazione di una variabile aleatoria $x\in\mathbb{N}^n$ e da una successione finita crescente di tempi $t\in\mathbb{R}^n$, è necessario ottimizzare i parametri di fitting che definiscono la funzione $f(n)$. In generale la funzione da scegliersi dovrebbe avere delle proprietà teoriche abbastanza note e se possibile essere sufficientemente liscia da garantire il calcolo di derivata almeno al primo ordine. Infatti se così dovesse essere sarebbe possibile in generale usare la tecnica della salita del gradiente per trovare i parametri ottimi per massimizzare la log-likelihood.

Nel nostro caso la funzione è $C^{\infty}$ e perciò siamo in grado di derivare quante volte vogliamo, il che sarà centrale a fini di implementazione, ma non solo: difatti la semplicità della funzione ci permette di trovare analiticamente uno dei parametri ottimi del modello che permette di velocizzare il calcolo usando un algoritmo molto rapido.

Di conseguenza, al fine di massimizzare \eqref{fitness_exp} cerchiamo i punti critici della funzione di fitness sul $k$-esimo blocco:
\begin{align*}
\log L_k(\tilde{x}) &= \sum_{i=1}^n\tilde{x}_i(\log\gamma + a\cdot(t_i-t_n)) -\int_{t_1}^{t_n}\gamma e^{a(t-t_n)} dt\\
&=N_k\log\gamma + a\tilde{x}_i\sum_{i=1}^n(t_i-t_n)-\gamma\left(\frac{1-e^{-aT_k}}{a}\right),
\end{align*}
dove $T_k$ è la lunghezza del temporale del blocco. Cerchiamo ora i punti critici:
\begin{align*}
\frac{\partial F_k(\tilde{x})}{\partial \gamma} = \frac{N_k}{\gamma} - \left(\frac{1-e^{-aT_k}}{a}\right)
\end{align*}
per cui, imponendola uguale a $0$, otteniamo 
$$
\gamma = \frac{aN_k}{1-e^{-aT_k}}.
$$
Di conseguenza,
\begin{align}\nonumber
F_{max,k}(\tilde{x}) &= N_k\log\left(\frac{aN_k}{1-e^{-aT_k}}\right) + a\sum_{i=1}^n\tilde{x}_i(t_i-t_n)-\frac{aN_k}{1-e^{-aT_k}}\left(\frac{1-e^{-aT_k}}{a}\right)\\ \nonumber
&= N_k\log\left(\frac{aN_k}{1-e^{-aT_k}}\right) + a\sum_{i=1}^n\tilde{x}_i(t_i-t_n)-N_k\\
&= N_k\left(\log\left(\frac{aN_k}{1-e^{-aT_k}}\right) + aS_k-1\right),\label{our_loglikel}
\end{align}
dove $S_k = \frac{1}{N_k}\sum_{i=1}^n\tilde{x}_i(t_i-t_n)$. 

Per valori sensibili di $N_k$ e $T_k$ la funzione è concava, perciò è sufficiente trovare un punto critico (se esiste) per trovare l'unico massimo. Siccome la funzione è di singola variabile e anche molto semplice da derivare, si è scelta una generalizzazione del metodo di Newton, il metodo di Halley, per trovare lo $0$ della derivata della nostra funzione $F_{max,k}$.

La scelta di questo algoritmo è dovuta sia a questioni di stabilità numerica che a questioni di velocità di convergenza.
\subsection{Estensioni al caso esponenziale e gaussiano}
\begin{remark}
Risulta interessante il caso in cui in ogni blocco la funzione sottostante non è soltanto del tipo $\gamma e^{a(t-t_n)}$ ma piuttosto $\gamma\left( e^{a(t-t_n)}+\lambda e^{-\left(\frac{t-\frac{t_1+t_n}{2}}{\sqrt{2}\sigma}\right)^2}\right)$, ovvero esponenziale più normale.

Utilizzando la statistica di Cash ottenuta in \eqref{Cash} cerchiamo di ottimizzare i parametri:
\begin{align*}
F(\tilde{x}) &= \sum_{i=1}^n\tilde{x}_i\log(f(t_i))-\int_{t_1}^{t_n}f(t) dt \\
&= \sum_{i=1}^{n}\tilde{x}_i\log\left(\gamma\left( e^{a(t_i-t_n)}+\lambda e^{-\left(\frac{t_i-\frac{t_1+t_n}{2}}{\sqrt{2}\sigma}\right)^2}\right)\right) - \gamma\int_{t_1}^{t_n}e^{a(t-t_n)} dt - \gamma\lambda\underbrace{\int_{t_1}^{t_n}e^{-\left(\frac{t-\frac{t_1+t_n}{2}}{\sqrt{2}\sigma}\right)^2}dt}_{G(\sigma)}\\
&= \underbrace{\sum_{i=1}^n\tilde{x}_i}_{N_k}\log\gamma + \sum_{i=1}^n\tilde{x}_i\log\left( e^{a(t_i-t_n)}+\lambda e^{-\left(\frac{t_i-\frac{t_1+t_n}{2}}{\sqrt{2}\sigma}\right)^2}\right)-\gamma\left(\frac{1-e^{-aT_k}}{a}\right)-\gamma\lambda G(\sigma)\\
&= N_k\log\gamma + \sum_{i=1}^n\tilde{x}_i\log\left( e^{a(t_i-t_n)}+\lambda e^{-\left(\frac{t_i-\frac{t_1+t_n}{2}}{\sqrt{2}\sigma}\right)^2}\right)-\gamma\left(\frac{1-e^{-aT_k}}{a}\right)-\gamma\lambda G(\sigma).
\end{align*}
Per trovare il massimo imponiamo uguale a 0 la derivata parziale in $\gamma$:
\begin{gather*}
\frac{\partial F}{\partial\gamma} = \frac{N_k}{\gamma}-\frac{1-e^{-aT_k}}{a}-\lambda G(\sigma)\stackrel{!}{=}0.
\end{gather*}
Per cui
$$
\gamma_{max} = \frac{aN_k}{1-e^{-aT_k}+a\lambda G(\sigma)}.
$$
Di conseguenza possiamo calcolare la statistica di Cash in corrispondenza del valore massimo di $\gamma$:
\begin{align*}
F_{max} &= F(\gamma_{max},a,\lambda,\sigma) \\
&= N_k\log\left(\frac{aN_k}{1-e^{-aT_k}+a\lambda G(\sigma)}\right) + \sum_{i=1}^n\tilde{x}_i\log\left( e^{a(t_i-t_n)}+\lambda e^{-\left(\frac{t_i-\frac{t_1+t_n}{2}}{\sqrt{2}\sigma}\right)^2}\right)-N_k.
\end{align*}
A seguire le derivate parziali di $F_{max}$, utili nel caso in cui si volesse implementare il calcolo degli ottimi parametri attraverso una salita del gradiente.
\begin{align*}
\frac{\partial F_{max}}{\partial a} &= N_k\left(\frac{1}{a}-\frac{\lambda G(\sigma)+e^{-a T_k}T_k}{1-e^{-aT_k}+a\lambda G(\sigma)}+\frac{1}{N_k}\sum_{i=1}^n\tilde{x}_i\frac{(t_i-t_n)e^{a(t_i-t_n)}}{e^{a(t_i-t_n)}+\lambda e^{-\left(\frac{t_i-\frac{t_1+t_n}{2}}{\sqrt{2}\sigma}\right)^2}}\right)\\
\frac{\partial F_{max}}{\partial \lambda} &= N_k\left(-\frac{a G(\sigma)}{1-e^{-aT_k}+a\lambda G(\sigma)}+\frac{1}{N_k}\sum_{i=1}^n\tilde{x}_i\frac{e^{-\left(\frac{t_i-\frac{t_1+t_n}{2}}{\sqrt{2}\sigma}\right)^2}}{e^{a(t_i-t_n)}+\lambda e^{-\left(\frac{t_i-\frac{t_1+t_n}{2}}{\sqrt{2}\sigma}\right)^2}}\right)\\
\frac{\partial F_{max}}{\partial\sigma} &= N_k\left(-\frac{a\lambda \frac{\partial G}{\partial\sigma}(\frac{t_1+t_n}{2},\sigma)}{1-e^{-aT_k}+a\lambda G(\sigma)}+\frac{1}{N_k}\sum_{i=1}^n\tilde{x}_i\frac{\lambda e^{-\left(\frac{t_i-\frac{t_1+t_n}{2}}{\sqrt{2}\sigma}\right)^2}\left(\frac{t_i-\frac{t_1+t_n}{2}}{\sigma}\right)^3}{e^{a(t_i-t_n)}+\lambda e^{-\left(\frac{t_i-t_n+\frac{t_1+t_n}{2}}{\sqrt{2}\sigma}\right)^2}}\right).
\end{align*}
\end{remark}
\subsection{Estensioni al caso esponenziale più costante}
\begin{remark}
Lavorando su dati reali risulta evidente che molto spesso ci si trova in una situazione dove c'è un rumore abbastanza costante su cui va a sommarsi un segnale che segue una certa legge, è quindi molto interessante gestire il caso in cui la nostra funzione di fitting è del tipo $\gamma(1+f(t))$ dove $f(t)$ si può pensare, a meno di una costante moltiplicativa $\gamma$, come la legge del segnale e $\gamma$ come la media del rumore. 

Vediamo il caso più generale possibile prima di entrare nel dettaglio di questa sottosezione. Con la statistica di Cash \eqref{Cash} usando $\gamma(1+f(t))$ otteniamo
\begin{align}
F(\tilde{x}) &= \sum_{i=1}^n\tilde{x}_i\log(\gamma(1+f(t_i)))-\int_{t_1}^{t_n}\gamma(1+f(t)) dt \nonumber\\
&= \underbrace{\sum_{i=1}^n\tilde{x}_i}_{N_k}\log\gamma + \sum_{i=1}^n\tilde{x}_i\log(1+f(t_i))-\gamma\underbrace{(t_n-t_1)}_{T_k}-\gamma\int_{t_1}^{t_n}f(t) dt\nonumber\\
&= N_k\log\gamma + \sum_{i=1}^n\tilde{x}_i\log(1+f(t_i)) -\gamma T_k -\gamma\int_{t_1}^{t_n}f(t) dt.\label{cash_gamma}
\end{align}
Per massimizzare $F$ prendiamo $\gamma$ così che il gradiente si annulli:
\begin{gather*}
\frac{\partial F}{\partial\gamma}=\frac{N_k}{\gamma}-T_k-\int_{t_1}^{t_n}f(t) dt\stackrel{!}{=}0
\end{gather*}
Per cui
\begin{equation}
\gamma = \frac{N_k}{T_k+\int_{t_1}^{t_n}f(t)dt}.\label{gamma_opt}
\end{equation}
Da cui la funzione da ottimizzare diventa
\begin{align}\nonumber
F_{max}(\tilde{x}) &= N_k\log\left(\frac{N_k}{T_k+\int_{t_1}^{t_n}f(t)dt}\right) + \sum_{i=1}^n\tilde{x}_i\log(1+f(t_i)) -\frac{N_k}{T_k+\int_{t_1}^{t_n}f(t)dt} \left(T_k +\int_{t_1}^{t_n}f(t) dt\right)\\
&= N_k\log\left(\frac{N_k}{T_k+\int_{t_1}^{t_n}f(t)dt}\right) + \sum_{i=1}^n\tilde{x}_i\log(1+f(t_i)) -N_k.\label{c_plus_cash_max}
\end{align}
\end{remark}
\begin{remark}
Usiamo i risultati del punto precedente con $f(t)=\lambda e^{a(t-t_n)}$:

Grazie a \eqref{c_plus_cash_max} troviamo che
\begin{align*}
F_{max}(\tilde{x}) &= N_k\log\left(\frac{N_k}{T_k+\int_{t_1}^{t_n}\lambda e^{a(t-t_n)}dt}\right) + \sum_{i=1}^n\tilde{x}_i\log(1+\lambda e^{a(t_i-t_n)}) -N_k\\
&= N_k\log\left(\frac{N_k}{T_k+\lambda \frac{1-e^{-aT_k}}{a}}\right) + \sum_{i=1}^n\tilde{x}_i\log(1+\lambda e^{a(t_i-t_n)}) -N_k\\
&= N_k\log\left(\frac{aN_k}{aT_k+\lambda \left(1-e^{-aT_k}\right)}\right) + \sum_{i=1}^n\tilde{x}_i\log(1+\lambda e^{a(t_i-t_n)}) -N_k.
\end{align*}
Usiamo le condizioni del primo ordine chiedendo che il gradiente si annulli per trovare i parametri che massimizzano questa statistica,
\begin{align*}
\frac{\partial F_{max}}{\partial a} &= \frac{N_k}{a}-N_k\frac{T_k+\lambda e^{-aT_k}T_k}{aT_k+\lambda \left(1-e^{-aT_k}\right)}+\sum_{i=1}^n\tilde{x}_i\frac{\lambda e^{a(t_i-t_n)}(t_i-t_n)}{1+\lambda e^{a(t_i-t_n)}}\stackrel{!}{=}0\\
\frac{\partial F_{max}}{\partial \lambda} &= -N_k\frac{1-e^{-aT_k}}{aT_k+\lambda \left(1-e^{-aT_k}\right)}+\sum_{i=1}^n\tilde{x}_i\frac{e^{a(t_i-t_n)}}{1+\lambda e^{a(t_i-t_n)}}\stackrel{!}{=}0.
\end{align*}
\end{remark}
\begin{remark}
Sarebbe molto ragionevole pensare che calcolando preventivamente la media del rumore si possa diminuire il numero di variabili da ottimizzare, sfortunatamente la realtà non è sempre ragionevole. Vediamo cosa succede se la variabile $\gamma$ fosse costante, partiamo da \eqref{cash_gamma}:
\begin{align*}
F(\tilde{x}) = N_k\log\gamma + \sum_{i=1}^n\tilde{x}_i\log(1+f(t_i)) -\gamma T_k -\gamma\int_{t_1}^{t_n}f(t) dt.
\end{align*}
Siccome questa è la log-likelihood di ogni blocco ed è additiva se $\gamma$ fosse costante sui blocchi la log-likelihood complessiva del dato sarebbe la somma su tutti i blocchi. Questo ha la importante conseguenza che i termini $N_k\log\gamma$ e $\gamma T_k$ possono essere scartati\footnote{Si usa in maniera centrale il fatto che $\gamma$ è costante sui blocchi, se così non fosse (che è il caso classico) non sarebbe possibile scartare questi termini.} in quanto sommando su tutti i blocchi $\sum T_k$ è la lunghezza temporale del dato e $\sum N_k$ è uguale alla somma di tutte le altezze dei bin di $x$. Per cui possiamo ridurci a
\begin{align*}
F(\tilde{x}) = \sum_{i=1}^n\tilde{x}_i\log(1+f(t_i)) -\gamma\int_{t_1}^{t_n}f(t) dt.
\end{align*}
Nel nostro caso specifico con $f(t)=\lambda e^{a(t-t_n)}$ otteniamo
\begin{align*}
F(\tilde{x}) = \sum_{i=1}^n\tilde{x}_i\log(1+\lambda e^{a(t_i-t_n)}) -\lambda\gamma\frac{1-e^{-aT_k}}{a}.
\end{align*}
Chiediamo ora le condizioni al primo ordine per massimizzare $F$:
\begin{align*}
\frac{\partial F}{\partial a} &= \sum_{i=1}^n\tilde{x}_i\frac{\lambda e^{a(t_i-t_n)}(t_i-t_n)}{1+\lambda e^{a(t_i-t_n)}}-\gamma\lambda\frac{aT_ke^{-aT_k}-1+e^{-aT_k}}{a^2}\stackrel{!}{=}0\\
\frac{\partial F}{\partial \lambda} &= \sum_{i=1}^n\tilde{x}_i\frac{e^{a(t_i-t_n)}}{1+\lambda e^{a(t_i-t_n)}}-\gamma\frac{1-e^{-aT_k}}{a}\stackrel{!}{=}0.
\end{align*}
Sfortunatamente nessuno dei termini permette di ottenere analiticameente $a$ o $\lambda$ in quanto sono rinchiusi all'interno della somma. Di conseguenza il numero di variabili da ottimizzare rimane $2$, non migliorando a livello di costo computazionale del caso precedente con il demerito di aver fatto una supposizione sul valore di $gamma$ che riduce la generalità del metodo.

\'E possibile utilizzare questa strategia ad hoc per diminuire il numero di variabili in uso, non essendo molto rigorosa per assicurarsi del suo funzionamento è necessario fare molte verifiche su dati reali e artificiali. L'idea di base è che in media possiamo approssimare $N_k$ con l'integrale della funzione di fitting:
\begin{equation}
N_k \approx \int_{t_1}^{t_n}\gamma\left(1+f(t)\right)dt.\label{approx_gamma}
\end{equation}
Notiamo che questo è vero soltanto in media: essendo $N_k=\sum_{i=1}^nX_i$, dove $X_i$ sono variabili aleatorie indipendenti con distribuzione di Poisson, valgono le formule 
\begin{gather*}
\mathbb{E}[N_k]=\sum_{i=1}^n\mathbb{E}[X_i],\\
var(N_k)=\sum_{i=1}^nvar(X_i),
\end{gather*}
per cui, specie se il valore della realizzazione degli $X$ è grande l'approssimazione \eqref{approx_gamma} potrebbe essere abbastanza errata, per questa ragione successivamente sono state svolte delle stime sull'errore. Ad ogni modo se l'approssimazione fosse abbastanza buona potrebbe essere possibile invertirla per ricavare $\gamma$ o i parametri che definiscono $f(t)$. 

Di conseguenza
\begin{align*}
\gamma \approx \frac{N_k}{T_k+\int_{t_1}^{t_n}f(t)dt},
\end{align*}
che è la stessa formula ottenuta in \eqref{gamma_opt} per cercare il $\gamma$ ottimo a fini di ottimizzazione, un'altra ragione che da un po' di merito a questa approssimazione.

Nel caso specifico di $f(t)=\lambda e^{a(t-t_n)}$ possiamo invertire questa formula per ricavare la variabile $\lambda$:
$$
\gamma\approx\frac{N_k}{T_k+\lambda\int_{t_1}^{t_n}e^{a(t-t_n)}dt},
$$
che diventa
\begin{align*}
\lambda&\approx\frac{N_k-\gamma T_k}{\gamma\int_{t_1}^{t_n}e^{a(t-t_n)}dt}\\
&\approx a\frac{N_k-\gamma T_k}{\gamma(1-e^{-aT_k})}.
\end{align*}
Di conseguenza calcolando il rumore medio $\gamma$ e passandolo al metodo come parametro e poi utilizzando questa euristica si può ottenere una formula chiusa per $\lambda$ in funzione di $a$ e $\gamma$, dopodichè si può calcolare numericamente $a$, così il numero delle variabili da ottimizzare numericamente è calato fino a $1$.

Infatti sostituendo nella statistica di Cash il valore di $\lambda$ ricordandosi che $\gamma$ in questo caso è un parametro si ottiene
\begin{align*}
F(\tilde{x}) &= N_k\log\gamma+\sum_{i=1}^n\log\left(1+a\frac{N_k-\gamma T_k}{\gamma(1-e^{-aT_k})}e^{a(t_i-t_n)}\right)-\gamma\left(T_k+ a\frac{N_k-\gamma T_k}{\gamma(1-e^{-aT_k})} \frac{1-e^{-aT_k}}{a}\right)\\
&= N_k\log\gamma+\sum_{i=1}^n\tilde{x_i}\log\left(1+\frac{N_k-\gamma T_k}{\gamma}\underbrace{a\frac{e^{a(t_i-t_n)}}{1-e^{-aT_k}}}_{Q(t_i,a)}\right)-N_k.
\end{align*}
Siccome $\gamma$ è costante sui blocchi possiamo scartare il primo e l'ultimo addendo, per cui la funzione di fitness diventa
$$
F(\tilde{x}) = \sum_{i=1}^n\tilde{x_i}\log\left(1+\frac{N_k-\gamma T_k}{\gamma}Q(t_i,a)\right).
$$
Per chiedere le condizioni al primo ordine per massimizzare $a$ dobbiamo imporre la derivata nulla:
$$
\frac{\partial F}{\partial a} = \sum_{i=1}^n\tilde{x}_i\frac{1}{1+\frac{N_k-\gamma T_k}{\gamma}Q(t_i,a)}\frac{N_k-\gamma T_k}{\gamma}\frac{\partial Q}{\partial a}(t_i,a)\stackrel{!}{=}0,
$$
dove
\begin{align*}
\frac{\partial Q}{\partial a}(t_i,a) &= \frac{e^{a(t_i-t_n)}}{1-e^{-aT_k}} + a\frac{(t_i-t_n)(1-e^{-aT_k})e^{a(t_i-t_n)}-T_ke^{-aT_k}e^{a(t_i-t_n)}}{(1-e^{-aT_k})^2}\\
&= \frac{e^{a(t_i-t_n)}}{1-e^{-aT_k}}\left(1+a\frac{(t_i-t_n)(1-e^{-aT_k})-T_ke^{-aT_k}}{1-e^{-aT_k}}\right).
\end{align*}
\end{remark}
\begin{remark}
Per chi fosse interessato seguono stime sull'errore dovuto alla approssimazione del punto precedente, in particolare come questo si propaga sul termine $\lambda$.

Trattiamo intanto il caso generale. Quando abbiamo applicato l'approssimazione \eqref{approx_gamma} abbiamo introdotto due tipi di errori:
\begin{itemize}
\item Siccome $N_k$ è somma di v.a. con distribuzioni Poisson indipendenti allora $N_k$ sarà v.a. con distribuzione Poisson di parametro uguale alla somma dei parametri delle $X_i$ ovvero $N_k\sim \mathcal{P}(\sum_{i=1}^n\tilde{f}(t_i))=\mathcal{P}(\gamma\sum_{i=1}^n(1+f(t_i)))$ ma noi l'abbiamo approssimato con la sua media $\sum_{i=1}^n\tilde{f}(t_i)$. La distribuzione Poisson è univariata e perciò segue la regola "68-95-99.7": nel $99.7\%$ dei casi una realizzazione di $N_k$ si troverà a meno di $3\sigma$ dalla sua media dove $\sigma$ è la deviazione standard di $N_k$.
\item Siccome la media di $N_k$ è una somma di Riemann l'abbiamo approssimata con un integrale così che svolgere i calcoli sia molto più agevole, ciò introduce un errore. Se supponiamo che $\tilde{f}(t)$ sia una funzione monotona è possibile stimare l'errore con $|\tilde{f}(t_n)-\tilde{f}(t_1)|$; questo è un risultato classico basato sul fatto che per funzioni monotone l'integrale giace sempre tra la somma di Riemann destra e quella sinistra.
\end{itemize}
Nel peggiore dei casi questi errori potrebbero sommarsi e quindi se definiamo 
$$
\epsilon = N_k - \int_{t_1}^{t_n}\tilde{f}(t)dt,
$$
avremo, forti delle due osservazioni fatte in precedenza che $|\epsilon|\leq3\sqrt{\lambda_{N_k}}+|\tilde{f}(t_n)-\tilde{f}(t_1)|$ nel $99.7\%$ dei casi\footnote{Se fosse necessaria più certezza è sufficiente sostituire il $3$ con un valore più alto.}.

Consideriamo ora la propagazione: siccome $N_k- \epsilon = \int_{t_1}^{t_n}\tilde{f}(t)dt$ possiamo ricavare le medesime formule ottenute in precedenza nel caso $\tilde{f}(t)=\gamma(1+\lambda e^{a(t-t_n)})$ e notare\footnote{I calcoli si basano sull'ipotesi che la larghezza dei bin sia sempre di $1$, se così non fosse bisognerebbe aggiungere un fattore correttivo relativo alla scala temporale usata.} che
\begin{align*}
\lambda &= a\frac{N_k-\epsilon-\gamma T_k}{\gamma(1-e^{-aT_k})}\\
&= a\frac{N_k-\gamma T_k}{\gamma(1-e^{-aT_k})} - a\frac{\epsilon}{\gamma(1-e^{-aT_k})}.
\end{align*}
Quindi il valore di $\lambda$ calcolato differisce da quello vero per un termine lineare in $\epsilon$. Stimiamolo ulteriormente:
$$
\epsilon_{\lambda}=\frac{\epsilon}{\gamma\left(\frac{1-e^{-aT_k}}{a}\right)}\leq \frac{3\sqrt{\gamma\sum_{i=1}^n(1+\lambda e^{a(t_i-t_n)})}}{\gamma\left(\frac{1-e^{-aT_k}}{a}\right)} + a\lambda
$$
Stimiamo la somma di Riemann nella radice sommando e sottraendo l'associato integrale
\begin{align*}
\epsilon_{\lambda}&\leq \frac{3\sqrt{|\tilde{f}(t_n)-\tilde{f}(t_1)|}}{\gamma\left(\frac{1-e^{-aT_k}}{a}\right)} + \frac{3\sqrt{\gamma T_k + \gamma\lambda\left(\frac{1-e^{-aT_k}}{a}\right)}}{\gamma\left(\frac{1-e^{-aT_k}}{a}\right)}+a\lambda\\
&\leq \frac{3\sqrt{\gamma\lambda|1-e^{-aT_k}|}}{\gamma\left(\frac{1-e^{-aT_k}}{a}\right)} + \frac{3\sqrt{\gamma T_k + \gamma\lambda\left(\frac{1-e^{-aT_k}}{a}\right)}}{\gamma\left(\frac{1-e^{-aT_k}}{a}\right)}+a\lambda\\
&\leq a\left(\lambda+\frac{3\sqrt{\lambda}}{\sqrt{\gamma|1-e^{-aT_k}|}}+\frac{3\sqrt{T_k+\lambda\frac{1-e^{-aT_k}}{a}}}{\sqrt{\gamma}(1-e^{-aT_k})}\right),
\end{align*}
che è l'errore assoluto su $\lambda$. Notiamo che su casi reali solitamente questo errore è abbastanza piccolo (errore relativo al più del $2\%$) e anche aumentando l'intervallo di confidenza di $N_k$ non cresce velocemente.
\end{remark}
\section{Implementazione}
Per fare quanto descritto sopra ci appoggiamo alla libreria Astropy per l'implementazione dell'algoritmo di Scargle (Bayesian Blocks) nel caso generale. Per implementare la funzione di fitness per il caso esponenziale si è scelto di estendere la classe \texttt{Events}, che implementa l'algoritmo nel caso di funzione di fitting costante. Difatti modificando il metodo \texttt{fit} è possibile mantenere tutta la struttura dell'algoritmo e cambiare soltanto il calcolo della funzione di fitness.

Per applicare il metodo implementato è sufficiente fare:
\begin{verbatim}
from astropy import bayesian_blocks
from bb_exponential import ExponentialBlocks_Events
bayesian_blocks(t,x,fitness=ExponentialBlocks_Events,ncp_prior=***,ncp_fun=***)
\end{verbatim}
Il parametro opzionale \texttt{ncp\_prior} è possibile specificarlo a priori oppure lasciare la sua determinazione al calcolatore. Le specifiche sul calcolo automatico di un buon \texttt{ncp\_prior} verranno trattate nei prossimi capitoli.

Il parametro opzionale \texttt{ncp\_fun} è una funzione che permette il calcolo di \texttt{ncp\_prior} a partire da \texttt{x}. Questo è utile specificarlo se si volesse usare la classe \texttt{ExponentialBlocks\_Events} su altri tipi di dati rispetto a quelli default. In tal caso infatti scelte diverse di \texttt{ncp\_prior} possono formare un algoritmo più sensibile o più robusto in base alle necessità sul tipo specifico di dato. Se vengono dati in input sia \texttt{ncp\_fun} che \texttt{ncp\_prior} sarà \texttt{ncp\_prior} ad avere priorità.

La funzione \texttt{bayesian\_blocks} però ritorna solamente gli estremi dei nostri blocchi e non anche i parametri calcolati per la funzione di ottimo fitting sui blocchi.
La scelta che si è fatta è stata quella di ricalcolare i parametri a fine esecuzione. Si riconosce che dal punto di vista del mero costo computazionale questa non è la scelta migliore (è necessario ricalcolare i parametri in un secondo tempo), tuttavia le motivazioni sono le seguenti:
\begin{itemize}
\item Il ricalcolo dei parametri è il comportamento della libreria Astropy; estenderlo per avere in output sia gli estremi che i parametri richiede la riscrittura quantomeno del metodo \texttt{fit} della classe \texttt{FitnessFunc} di Astropy, affinchè in fase di "peeling off" dell'array \texttt{last}, oltre al calcolo dell'ottimo estremo, si ottengano anche i parametri ottimi. L'implementazione di questo procedimento sarebbe lenta e romperebbe la compatibilità con precedenti implementazioni.
\item Il costo computazionale è sì maggiore, ma di una quantità piuttosto irrisoria rispetto al costo dell'algoritmo. Infatti l'algoritmo di programmazione dinamica durante l'esecuzione richiede di effettuare il calcolo di fitting sull'ultimo blocco $O(N^2)$, invece il costo di calcolo sul singolo blocco si può pensare come costante; di conseguenza, dato che ci si aspetta che il numero di blocchi identificati sia molto più piccolo rispetto al numero di bins, il costo di ricalcolo risulta irrisorio rispetto al calcolo di partizionamento ottimo.
\end{itemize}
Dal punto di vista applicativo il ricalcolo è implementato mediante il metodo \texttt{get\_parameters} della classe \texttt{ExponentialBlocks\_Events} nella seguente maniera:
\begin{verbatim}
edges = bayesian_blocks(t,x,fitness=ExponentialBlocks_Events, ncp_prior=***)
edge_l,edge_r = edges[0],edges[1]
params = ExponentialBlocks_Events(ncp_prior=***).get_parameters(edge_l,edge_r,t,x)
\end{verbatim}
e i parametri vengono restituiti come un dizionario di chiavi \texttt{a} e \texttt{gamma}.

Tale metodo deve essere iterato su ogni coppia di estremi per ottenere i parametri di ogni blocco.
\section{Ottimizzazione iperparametri}
Il modello è non parametrico, quindi sembrerebbe che non ci siano parametri da ottimizzare in quanto questi vengono già ottimizzati dall'algoritmo in fase di esecuzione. Sorge però un problema: è necessario controllare il numero di blocchi identificati.

Per semplificare il processo possiamo pensare che il numero di blocchi identificati e la variabile aleatoria di cui i dati $x$ sono una realizzazione siano indipendenti. Facendo questo la likelihood complessiva sarà il prodotto tra le likelihood dei dati in ogni blocco e la likelihood del numero di blocchi identificati.

Sarebbe possibile dare qualunque tipo di distribuzione discreta alla variabile aleatoria del numero di blocchi; tuttavia si sceglie di usare una distribuzione geometrica in quanto ci aspettiamo che ci sia un maggiore peso da dare a piccoli numeri di blocchi rispetto a grandi numeri. Di conseguenza fissiamo 
$$P(N_{blocks}=n)=P_0\cdot\alpha^n\cdot\mathds{1}(n\leq N)$$
con $\alpha\in(0,1)$ e $P_0$ costante di normalizzazione.

Naturalmente è possibile calcolare che $P_0 = \frac{1-\alpha}{1-\alpha^{N+1}}$.

Avendo calcolata questa likelihood, alla fitness del blocco sarà necessario sommare $\log\alpha$ per normalizzare rispetto al numero di blocchi e rendere più improbabile una partizione con troppi o troppi pochi blocchi.

Si presenta ora il punto cruciale, ovvero il calcolo della costante $ncp\_prior=\log\alpha$. \'E evidente la sua dipendenza dal numero di bin $N$, ma è possibile notare che più è alto il valore atteso della variabile aleatoria $N_{blocks}$, più è probabile che ci siano falsi positivi, ovvero che venga identificato l'estremo di un blocco quando in realtà questo non dovrebbe succedere. Non sono note formule esatte, però è possibile seguire una di queste tecniche empiriche per trovare la scelta ottima (o quantomeno abbastanza\footnote{Il metodo è sufficientemente rigido da restituire i medesimi risultati a patto che questo parametro sia anche soltanto vicino a quello ottimo. Dal punto di vista matematico ciò è triviale in quanto il numero di blocchi identificati è una variabile discreta, mentre $ncp\_prior$ è un parametro continuo.} buona) di $ncp\_prior$:
\begin{enumerate}
\item Se è possibile generare dati artificiali (simili a quelli su cui poi l'algoritmo dovrà essere applicato), si può testare l'algoritmo su vari valori possibili di $ncp\_prior$ e poi calcolare $p\_0$ rispetto a questi; infine, si sceglie il valore di $ncp\_prior$ più basso (così che l'algoritmo sia il più sensibile possibile) che garantisca un false detection rate minore di un valore fissato in precedenza, $0.05$ ad esempio. Bisogna tenere conto tuttavia della dipendenza del parametro da $N$: sarà quindi necessario farlo per molteplici valori di $N$.
\item Se si facesse esattamente come da punto $1$ bensì su dati reali, questo potrebbe produrre dell'overfitting, e perciò è preferibile utilizzare $k$-cross-validation\footnote{Presi i dati reali questi si suddividono casualmente in $k$ sottoinsiemi della stessa cardinalità, dopodichè iterativamente si prende l'$i$-esimo sottoinsieme, che sarà l'insieme di verifica, e tutti gli altri, che saranno i nostri dati di allenamento. Si ottimizza la scelta di $ncp\_prior$ sui dati di allenamento rispetto a qualche funzione di fitness (ad esempio il numero di blocchi identificati, l'errore quadratico medio o il false detection rate). Successivamente si calcola la medesima fitness sui dati di verifica e si usa quel valore per confrontare i risultati al variare dell'$ncp\_prior$. Quello che massimizza la fitness sui dati di verifica è l'$ncp\_prior$ che viene scelto.}.
\item Esiste un'ulteriore tecnica che non viene qui riportata, che si può consultare nella sezione 2.7 di Scargle (2013).
\end{enumerate}
Una volta che sono state fatte queste stime si può applicare un'interpolazione su questi dati per avere una stima di $ncp\_prior$ in funzione di $p\_0$ e di $N$.

Nell'implementazione si è scelta una interpolazione tramite spline sui dati costruiti con $p\_0$ uguale a $0$ per semplicità. \'E possibile trovare i dati di interpolazione nel codice sorgente.

\section{Osservazioni senza particolare ordine}
\begin{remark}
In fase di calcolo della log-likelihood la nostra funzione \eqref{our_loglikel} non ha un buon comportamento computazionale: ad esempio, se la variabile $a$ risulta negativa il termine $-aT_k$ potrebbe essere abbastanza alto da causare un overflow nell'esponenziale; l'algoritmo in tal caso non ha problemi in quanto risulterebbe una log-likelihood sul blocco di $-\infty$, però questo potrebbe ostacolare l'ottimizzazione. Analogamente se $a$ risulta troppo vicino allo $0$ potrebbe succedere che l'argomento del $\log$ può esplodere se il denominatore dovesse diventare $0$ esatto. Per questi due casi si propongono due approssimazioni numeriche che dovrebbero evitare questo genere di problemi:
\begin{itemize}
\item Tramite lo sviluppo di Taylor dell'esponenziale in caso di $a$ vicino allo 0 è possibile approssimare \eqref{our_loglikel} con
$$
N_k\left(\log\left(\frac{N_k}{T_k}\right)+aS_k-1\right).
$$
\item Se $a$ dovesse risultare molto minore di $0$ l'esponenziale dominerebbe il termine $1$; in tal caso si può ignorare il termine 1 a denominatore, di conseguenza approssimiamo \eqref{our_loglikel} con 
$$
N_k\left(aT_k+\log(-aN_k)+aS_k-1\right).
$$
\end{itemize}
\end{remark}
\begin{remark}
Quando si usa questo algoritmo è importante notare che le funzioni esponenziali ci permettono di avere molta più flessibilità. Tuttavia, messo a confronto anche semplicemente con Bayesian Blocks con funzione di fitting costante questo algoritmo non è strettamente migliore: ha infatti sia alcune potenzialità che alcuni problemi che nel sopracitato metodo non compaiono.
\begin{itemize}
\item \'E proprio della natura della funzione esponenziale la velocità nel crescere: questo permette di rappresentare alcuni tipi particolari di dati con grande fedeltà. Bisogna comunque fare attenzione al pericolo che ciò comporta: se il metodo fallisse, ad esempio per una scelta sbagliata del parametro $ncp\_prior$, questo potrebbe avvenire in maniera esplosiva. Perciò è fondamentale scegliere correttamente il parametro in questione per avere dei risultati attendibili.
\item Il calcolo dei parametri è molto più costoso a causa della non esistenza di una soluzione analitica del massimo della log-likelihood. Per cui se il costo computazionale dovesse essere una priorità il metodo trattato potrebbe non essere (almeno direttamente) il più adatto.
\end{itemize}
\end{remark}
\end{document}